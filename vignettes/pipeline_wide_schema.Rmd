---
title: "Introduction to cytominr"
author: "Allen Goodman and Shantanu Singh"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to cytominr}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(magrittr)
futile.logger::flog.threshold(futile.logger::WARN)
```


Typical morphological profiling datasets have millions of cells 
and hundreds of features per cells. When working with this data, you must

- clean the data

- normalize the features so that they are comparable across experiments

- transform the features so that their distributions are well-behaved (
i.e., bring them in line with assumptions we want to make about their 
disributions) 

- select features based on their quality

- aggregate the single-cell data, if needed

The cytominr package makes these steps fast and easy.

## Load data
First, load the data, which is stored in a database backend created using 
https://github.com/0x00B1/persistence.

This vignette uses a backend that is specified in the environment variable
`CYTOMINR_SQLITE_FILE`. To set it, add it to the `.Renviron` in your home 
directory:
`CYTOMINR_SQLITE_FILE=~/Desktop/example.sqlite`

```{r}
fixture <- Sys.getenv("CYTOMINR_SQLITE_FILE")

db <- dplyr::src_sqlite(path = fixture)

```

Then load associated metadata if it exists

```{r}
ext_metadata <-
  readr::read_csv(system.file("extdata", "metadata.csv",
                              package = "cytominr")) %>%
  dplyr::rename(g_well = Well)

```


```{r}
futile.logger::flog.info("Creating table for objects")

image <- dplyr::tbl(src = db, "image")

object <-
  dplyr::tbl(src = db, "cells") %>%
  dplyr::inner_join(dplyr::tbl(src = db, "cytoplasm"),
                    by = c("TableNumber", "ImageNumber", "ObjectNumber")) %>%
  dplyr::inner_join(dplyr::tbl(src = db, "nuclei"),
                    by = c("TableNumber", "ImageNumber", "ObjectNumber"))

object %<>% dplyr::inner_join(image %>%
                                dplyr::select(TableNumber,
                                              ImageNumber,
                                              image_Metadata_Barcode,
                                              image_Metadata_Well,
                                              image_Metadata_isDebris) ,
                              by = c("TableNumber", "ImageNumber")) %>%
  dplyr::rename(g_plate = image_Metadata_Barcode,
                g_well = image_Metadata_Well,
                g_table = TableNumber,
                g_image = ImageNumber,
                q_debris = image_Metadata_isDebris)

futile.logger::flog.info("Created table for objects")

```


How many rows does this table have?

```{r}
object %>%
  dplyr::tally() %>%
  knitr::kable()
```


```{r}
measurements <- object %>% dplyr::collect(n = Inf)
```


```{r}
qc_cols <- c("q_debris")

group_cols <-
  c("g_plate",
    "g_well",
    "g_table",
    "g_image")

feature_cols <-
  colnames(measurements) %>%
  stringr::str_subset("^Nuclei_|^Cells_|^Cytoplasm_")

testthat::expect_true(all(group_cols %in% (
  colnames(measurements) %>%
    stringr::str_subset("^g_")
)))

testthat::expect_true(all(qc_cols %in% (
  colnames(measurements) %>%
    stringr::str_subset("^q_")
)))

measurements %<>%
  dplyr::select(dplyr::one_of(c(group_cols, qc_cols, feature_cols)))

```

## Clean

Let's remove cells that come from images that were marked as having debris

```{r}
measurements %<>% dplyr::filter(q_debris == 0)
```

### Normalize 

We need to normalize the data so that

- features are on the same scale

- plate-to-plate variation is reduced

The default for doing this is `standardization`. Here, we take all the cells
from control wells in the experiment (this is where the external metadata gets
used) and compute normalizations parameters from that (in this case, just the
mean and s.d.) and then apply it to the whole dataset (i.e. the population)

```{r}
measurements <-
   cytominr::normalize(
    population = measurements,
    variables = feature_cols,
    strata =  c("g_plate"),
    sample =
      measurements %>%
      dplyr::inner_join(
        ext_metadata %>% dplyr::filter(Type == "ctrl") %>%
          dplyr::select(g_well)
      )
  )

```

In some cases, we may have features that have no variance at all (e.g. Euler 
number). If these features have not already been removed by this stage, the 
standardization step will results in all values for that feature being NA (
because s.d. = 0). Lets remove them:

First, count how many cells have NA values per feature:

```{r}
na_frequency <-
   cytominr::count_na_rows(
    population = measurements,
    variables = feature_cols)

na_frequency %<>%
  tidyr::gather(feature, na_count) %>%
  dplyr::filter(na_count > 0) %>%
  dplyr::mutate(na_percent = na_count / nrow(measurements)) 

na_frequency %>%
  knitr::kable()

```

Lets run this cleaning operation

```{r}

measurements <-
  cytominr::select(
    population = measurements,
    variables = feature_cols,
    operation = "drop_na_columns"
)

feature_cols %<>% intersect(names(measurements))
```


## Select features

Finally, we typically perform feature selection on the data (TODO: explain 
further). Feature selection is an expensive operation, so we usually want to 
train the feature selection model on a sample of the dataset. Here, we choose
to aggregate the data instead of sampling it (i.e. collapse it to per-well
aggregates)

```{r}
aggregated <-
  cytominr::aggregate(
    population = measurements,
    variables = feature_cols,
    strata = c("g_plate", "g_well")
  ) 
```

... and then apply feature selection on the per-cell data. 
```{r}
selected <-
  cytominr::select(
    population = measurements,
    variables = feature_cols,
    sample = aggregated,
    operation = "correlation_threshold"
  ) 
```

And now lets take a glimpse at the data!
```{r}
selected %>%
  dplyr::glimpse()
```

